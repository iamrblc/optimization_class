{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION TO OPTIMIZATION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the right language\n",
    "Let's see a problem that takes time, adding up the first billion numbers. \n",
    "\n",
    "In Python you can do it by using a loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "N = 1000_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to add them up \"manually\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop total: 499999999500000000\n",
      "Loop time: 46.79621720314026 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "total_loop = 0\n",
    "for i in range(N):\n",
    "    total_loop += i\n",
    "\n",
    "print(f\"Loop total: {total_loop}\")\n",
    "print(f\"Loop time: {time.time() - start} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it took some time even on a strong machine. Let's try the same with Python's native `sum()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum total: 499999999500000000\n",
      "Sum time: 7.801518201828003 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "total_sum = sum(range(N))\n",
    "print(f\"Sum total: {total_sum}\")\n",
    "print(f\"Sum time: {time.time() - start} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was much faster. When python runs this function, there is a low level language running in the background, similar to this `C++` script:\n",
    "\n",
    "```cpp\n",
    "#include <iostream>\n",
    "#include <chrono>\n",
    "\n",
    "int main() {\n",
    "auto start = std::chrono::high_resolution_clock::now();\n",
    "long long total = 0;\n",
    "for (int i = 0; i < 1000000000; ++i) total += i;\n",
    "std::cout << total << std::endl;\n",
    "auto end = std::chrono::high_resolution_clock::now();\n",
    "std::chrono::duration<double> diff = end - start;\n",
    "std::cout << \"Time: \" << diff.count() << \" s\\n\";\n",
    "return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "### Interpreted vs Compiled languages\n",
    "\n",
    "A **compiled language** (like C++) translates the entire code into machine instructions **before** it runs. So when you execute it, it's already in the fastest form your computer understands.\n",
    "\n",
    "An **interpreted language** (like Python) reads and executes code **line by line**, while the program is running. This makes it more flexible and easy to write, but slower because it's doing more work at runtime.\n",
    "\n",
    "Thatâ€™s why Python is often used for prototyping. It may be too slow for really big tasks, but it's easy to write and debug. Once the code is running as intended, you can \"translate\" it to a low level language. \n",
    "\n",
    "### JIT - Just In Time Compilation\n",
    "There are languages that were developed specifically for scientific computing, such as Matlab or Julia. The latter is especially known for being \"easy as Python, fast as C\". \n",
    "\n",
    "Julia looks like an interpreted language (just like Python), but in reality it uses **just in time compliation (JIT)**. It doesn't compile the entire code before it runs (like C), but compiles parts of it as needed, on the go. \n",
    "\n",
    "While Juila or Matlab were designed to be able to do this there are also Python packages (such as `numba`) that enable JIT.\n",
    "\n",
    "```julia\n",
    "@time total = sum(0:999_999_999)\n",
    "println(total)\n",
    "```\n",
    "(Note that Julia uses 1-indexing instead of 0-indexing, similar to R.)\n",
    "\n",
    "You may notice that the runtime was extremely low. But how can it be even faster than a language close to machine code?\n",
    "\n",
    "In scientific computing languages like Julia, many mathematical patterns are recognized and mapped to hardcoded optimizations. In this case, Julia detects that ranges like `(n:m)` are a special case for `sum()` and uses a fast, pre-optimized formula instead of looping (here a `UnitRange` method).\n",
    "\n",
    "Conceptually, this is similar to the trick the little Gauss allegedly used to sum numbers quickly:\n",
    "\n",
    "$\\sum_{i=1}^{n} i = \\frac{n(n+1)}{2}$\n",
    "\n",
    "Take home message: using your brain can speed up your code. ðŸ™ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum total: 499999999500000000\n",
      "Sum time: 0.00015211105346679688 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "n = N - 1\n",
    "total_sum = n * (1 + n) // 2\n",
    "print(f\"Sum total: {total_sum}\")\n",
    "print(f\"Sum time: {time.time() - start} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See?\n",
    "\n",
    "### Self check questions\n",
    "When is it worth to use a compiled languge?<br>\n",
    "Why is Python widely used in scientific tasks despite its slow performance?<br>\n",
    "What makes Julia \"as easy as Python and as fast as C\"?<br>\n",
    "What happens when you sum random numbers instead of a range?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to parallel computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add up 100 thousand random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49998298.34697442\n",
      "5.654012203216553\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from random import random, seed\n",
    "seed(42)\n",
    "\n",
    "start = time()\n",
    "print(sum([random() for _ in range(100_000_000)]))\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical CPUs (threads): 8\n",
      "Physical cores: 8\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "print(\"Logical CPUs (threads):\", psutil.cpu_count(logical=True))\n",
    "print(\"Physical cores:\", psutil.cpu_count(logical=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, multiprocessing and Jupyter notebook don't go well hand-in-hand, so consult the README.md for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate random FASTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file generated at ../data/sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_fasta(file_path, num_sequences=1000, seq_length=1000):\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    with open(file_path, 'w') as f:\n",
    "        for i in range(num_sequences):\n",
    "            seq_id = f\">seq{i+1}\\n\"\n",
    "            sequence = ''.join(random.choices(bases, k=seq_length)) + '\\n'\n",
    "            f.write(seq_id)\n",
    "            f.write(sequence)\n",
    "\n",
    "output_path = '../data/sequences.fasta'\n",
    "generate_fasta(output_path, num_sequences=10, seq_length=1000)\n",
    "print(f\"FASTA file generated at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rblc/ELTE/optimization_class/.venv/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
